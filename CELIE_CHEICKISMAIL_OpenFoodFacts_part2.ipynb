{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903f220a",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning for NLP and Text Processing\n",
    "## Project 1 : OpenFoodFacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import mpld3\n",
    "import random\n",
    "# mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-impression",
   "metadata": {},
   "source": [
    "### Read csv obtain from part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './dataset/openfoodfacts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(PATH, sep = '\\t') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-bunch",
   "metadata": {},
   "source": [
    "### Clean remove the entries impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  dataset[dataset[\"energy-kcal_100g\"] < 15000] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-portugal",
   "metadata": {},
   "source": [
    "### Number of entries per categories\n",
    "Check number in each category to see which one to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-customs",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9d97b6cdf19e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pnns_groups_1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"product_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.groupby(\"pnns_groups_1\").count()[\"product_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-hypothetical",
   "metadata": {},
   "source": [
    "## Clustering approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-simpson",
   "metadata": {},
   "source": [
    "### Remove NA\n",
    "We have chosen to study the most relevant and filled columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(subset=[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-experience",
   "metadata": {},
   "source": [
    "### Define X\n",
    "We choose here to first study **Cereals and potatoes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (dataset[dataset[\"pnns_groups_1\"]==\"Cereals and potatoes\"])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-florence",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-irrigation",
   "metadata": {},
   "source": [
    "Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sudden-correspondence",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eb11cf6787ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KMeans' is not defined"
     ]
    }
   ],
   "source": [
    "model=KMeans()\n",
    "label = model.fit_predict(X)\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-michigan",
   "metadata": {},
   "source": [
    "Display of the result on two by two graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = np.array([ np.random.choice(range(256), size=3)/256 for j in range(len(label))])\n",
    "plt.rcParams[\"figure.figsize\"]=20,20\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "axs[0, 0].scatter(X[\"energy-kcal_100g\"], X[\"energy_100g\"], s=1, c=cmap[label])\n",
    "axs[0, 0].set_title('energy-kcal_100g x energy_100g')\n",
    "axs[0, 1].scatter(X[\"energy-kcal_100g\"], X[\"fat_100g\"], s=1, c=cmap[label])\n",
    "axs[0, 1].set_title('energy-kcal_100g x fat_100g')\n",
    "axs[0, 2].scatter(X[\"energy-kcal_100g\"], X[\"saturated-fat_100g\"], s=1, c=cmap[label])\n",
    "axs[0, 2].set_title('energy-kcal_100g x saturated-fat_100g')\n",
    "axs[1, 0].scatter(X[\"energy-kcal_100g\"], X[\"carbohydrates_100g\"], s=1, c=cmap[label])\n",
    "axs[1, 0].set_title('energy-kcal_100g x carbohydrates_100g')\n",
    "axs[1, 1].scatter(X[\"energy-kcal_100g\"], X[\"sugars_100g\"], s=1, c=cmap[label])\n",
    "axs[1, 1].set_title('energy-kcal_100g x sugars_100g')\n",
    "axs[1, 2].scatter(X[\"energy-kcal_100g\"], X[\"fiber_100g\"], s=1, c=cmap[label])\n",
    "axs[1, 2].set_title('energy-kcal_100g x fiber_100g')\n",
    "axs[2, 0].scatter(X[\"energy-kcal_100g\"], X[\"proteins_100g\"], s=1, c=cmap[label])\n",
    "axs[2, 0].set_title('energy-kcal_100g x proteins_100g')\n",
    "axs[2, 1].scatter(X[\"energy-kcal_100g\"], X[\"salt_100g\"], s=1, c=cmap[label])\n",
    "axs[2, 1].set_title('energy-kcal_100g x salt_100g')\n",
    "axs[2, 2].scatter(X[\"energy-kcal_100g\"], X[\"sodium_100g\"], s=1, c=cmap[label])\n",
    "axs[2, 2].set_title('energy-kcal_100g x sodium_100g')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='x-label', ylabel='y-label')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-return",
   "metadata": {},
   "source": [
    "Let's see some elements of some clusters to try to understand the clusters made by the K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_labels = X.copy()\n",
    "X_with_labels[\"labels\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_with_labels[X_with_labels[\"labels\"]==0])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_with_labels[X_with_labels[\"labels\"]==1])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-heather",
   "metadata": {},
   "source": [
    "### K-means with PCA first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=2)\n",
    "pca_2_result = pca_2.fit_transform(X)\n",
    "print('Explained variation per principal component: {}'.format(pca_2.explained_variance_ratio_))\n",
    "print('Cumulative variance explained by 2 principal components: {:.2%}'.format(np.sum(pca_2.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(5)\n",
    "label = model.fit_predict(pca_2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-aluminum",
   "metadata": {},
   "source": [
    "Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=10,10\n",
    "cmap = np.array([ np.random.choice(range(256), size=3)/256 for j in range(len(label))])\n",
    "plt.scatter(pca_2_result[:,0], pca_2_result[:,1], s=1, c=cmap[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-export",
   "metadata": {},
   "source": [
    "Let's see some elements of some clusters to try to understand the clusters made by the K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_labels = X.copy()\n",
    "X_with_labels[\"labels\"] = label\n",
    "X_with_labels[\"product_name\"] = dataset[\"product_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_with_labels[X_with_labels[\"labels\"]==0])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-block",
   "metadata": {},
   "source": [
    "Let's see an summary of the outliers of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    print(col)\n",
    "    for _ in set(label):\n",
    "        print(f\"\\tLabel {_}\")\n",
    "\n",
    "#         Median\n",
    "        print(f\"\\t\\tMedian = {(X_with_labels[X_with_labels['labels']==_])[[ col ]].median()[0] }\" )\n",
    "\n",
    "#         Min    \n",
    "        print(f\"\\t\\tMin = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].min()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].min()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "            \n",
    "\n",
    "#         Max\n",
    "        print(f\"\\t\\tMax = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].max()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].max()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "\n",
    "        print(\"----------\")\n",
    "\n",
    "\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-macedonia",
   "metadata": {},
   "source": [
    "### K-means with PCA with log on energy and energy-kcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "X[\"energy-kcal_100g\"] = X[\"energy-kcal_100g\"].apply(lambda x : math.log(x) if x!=0 else 0)\n",
    "X[\"energy_100g\"] = X[\"energy_100g\"].apply(lambda x : math.log(x) if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=2)\n",
    "pca_2_result = pca_2.fit_transform(X)\n",
    "print('Explained variation per principal component: {}'.format(pca_2.explained_variance_ratio_))\n",
    "print('Cumulative variance explained by 2 principal components: {:.2%}'.format(np.sum(pca_2.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(5)\n",
    "label = model.fit_predict(pca_2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-choir",
   "metadata": {},
   "source": [
    "Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=10,10\n",
    "cmap = np.array([ np.random.choice(range(256), size=3)/256 for j in range(len(label))])\n",
    "plt.ylim(top=10)\n",
    "plt.scatter(pca_2_result[:,0], pca_2_result[:,1], s=1, c=cmap[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-quick",
   "metadata": {},
   "source": [
    "Let's see an summary of the outliers of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_labels = X_cap.copy()\n",
    "X_with_labels[\"labels\"] = label\n",
    "X_with_labels[\"product_name\"] = dataset[\"product_name\"]\n",
    "\n",
    "(X_with_labels[X_with_labels[\"labels\"]==0])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]].head()\n",
    "\n",
    "for col in X_cap.columns:\n",
    "    print(col)\n",
    "    for _ in set(label):\n",
    "        print(f\"\\tLabel {_}\")\n",
    "\n",
    "#         Median\n",
    "        print(f\"\\t\\tMedian = {(X_with_labels[X_with_labels['labels']==_])[[ col ]].median()[0] }\" )\n",
    "\n",
    "#         Min    \n",
    "        print(f\"\\t\\tMin = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].min()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].min()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "            \n",
    "\n",
    "#         Max\n",
    "        print(f\"\\t\\tMax = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].max()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].max()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "\n",
    "        print(\"----------\")\n",
    "\n",
    "\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-response",
   "metadata": {},
   "source": [
    "### Sugary snacks\n",
    "We tried the same approach on sugary snacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (dataset[dataset[\"pnns_groups_1\"]==\"Sugary snacks\"])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"energy-kcal_100g\"] = X[\"energy-kcal_100g\"].apply(lambda x : math.log(x) if x!=0 else 0)\n",
    "X[\"energy_100g\"] = X[\"energy_100g\"].apply(lambda x : math.log(x) if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=2)\n",
    "pca_2_result = pca_2.fit_transform(X)\n",
    "print('Explained variation per principal component: {}'.format(pca_2.explained_variance_ratio_))\n",
    "print('Cumulative variance explained by 2 principal components: {:.2%}'.format(np.sum(pca_2.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(5)\n",
    "label = model.fit_predict(pca_2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-rebecca",
   "metadata": {},
   "source": [
    "Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=10,10\n",
    "cmap = np.array([ np.random.choice(range(256), size=3)/256 for j in range(len(label))])\n",
    "plt.scatter(pca_2_result[:,0], pca_2_result[:,1], s=1, c=cmap[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-saudi",
   "metadata": {},
   "source": [
    "Let's see an summary of the outliers of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_labels = X_cap.copy()\n",
    "X_with_labels[\"labels\"] = label\n",
    "X_with_labels[\"product_name\"] = dataset[\"product_name\"]\n",
    "\n",
    "(X_with_labels[X_with_labels[\"labels\"]==0])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]].head()\n",
    "\n",
    "for col in X_cap.columns:\n",
    "    print(col)\n",
    "    for _ in set(label):\n",
    "        print(f\"\\tLabel {_}\")\n",
    "\n",
    "#         Median\n",
    "        print(f\"\\t\\tMedian = {(X_with_labels[X_with_labels['labels']==_])[[ col ]].median()[0] }\" )\n",
    "\n",
    "#         Min    \n",
    "        print(f\"\\t\\tMin = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].min()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].min()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "            \n",
    "\n",
    "#         Max\n",
    "        print(f\"\\t\\tMax = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].max()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].max()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "\n",
    "        print(\"----------\")\n",
    "\n",
    "\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-organizer",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "We tried another clustering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (dataset[dataset[\"pnns_groups_1\"]==\"Beverages\"])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"energy-kcal_100g\"] = X[\"energy-kcal_100g\"].apply(lambda x : math.log(x) if x!=0 else 0)\n",
    "X[\"energy_100g\"] = X[\"energy_100g\"].apply(lambda x : math.log(x) if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=2)\n",
    "pca_2_result = pca_2.fit_transform(X)\n",
    "print('Explained variation per principal component: {}'.format(pca_2.explained_variance_ratio_))\n",
    "print('Cumulative variance explained by 2 principal components: {:.2%}'.format(np.sum(pca_2.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=3.5, min_samples=5).fit(pca_2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-frontier",
   "metadata": {},
   "source": [
    "Display some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=10,10\n",
    "cmap = np.array([ np.random.choice(range(256), size=3)/256 for j in range(len(labels))])\n",
    "plt.ylim(top=10)\n",
    "plt.scatter(pca_2_result[:,0], pca_2_result[:,1], s=10, c=cmap[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=20,20\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "axs[0, 0].scatter(X[\"salt_100g\"], X[\"energy_100g\"], s=1, c=cmap[labels])\n",
    "axs[0, 0].set_title('energy-kcal_100g x energy_100g')\n",
    "axs[0, 1].scatter(X[\"salt_100g\"], X[\"fat_100g\"], s=1, c=cmap[labels])\n",
    "axs[0, 1].set_title('energy-kcal_100g x fat_100g')\n",
    "axs[0, 2].scatter(X[\"salt_100g\"], X[\"saturated-fat_100g\"], s=1, c=cmap[labels])\n",
    "axs[0, 2].set_title('energy-kcal_100g x saturated-fat_100g')\n",
    "axs[1, 0].scatter(X[\"salt_100g\"], X[\"carbohydrates_100g\"], s=1, c=cmap[labels])\n",
    "axs[1, 0].set_title('energy-kcal_100g x carbohydrates_100g')\n",
    "axs[1, 1].scatter(X[\"salt_100g\"], X[\"sugars_100g\"], s=1, c=cmap[labels])\n",
    "axs[1, 1].set_title('energy-kcal_100g x sugars_100g')\n",
    "axs[1, 2].scatter(X[\"salt_100g\"], X[\"fiber_100g\"], s=1, c=cmap[labels])\n",
    "axs[1, 2].set_title('energy-kcal_100g x fiber_100g')\n",
    "axs[2, 0].scatter(X[\"salt_100g\"], X[\"proteins_100g\"], s=1, c=cmap[labels])\n",
    "axs[2, 0].set_title('energy-kcal_100g x proteins_100g')\n",
    "axs[2, 1].scatter(X[\"salt_100g\"], X[\"salt_100g\"], s=1, c=cmap[labels])\n",
    "axs[2, 1].set_title('energy-kcal_100g x salt_100g')\n",
    "axs[2, 2].scatter(X[\"salt_100g\"], X[\"sodium_100g\"], s=1, c=cmap[labels])\n",
    "axs[2, 2].set_title('energy-kcal_100g x sodium_100g')\n",
    "\n",
    "for ligne in axs:\n",
    "    for _ in ligne:\n",
    "        _.set_xlim([0,10])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='x-label', ylabel='y-label')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-distinction",
   "metadata": {},
   "source": [
    "Let's see an summary of the outliers of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_labels = X_cap.copy()\n",
    "X_with_labels[\"labels\"] = label\n",
    "X_with_labels[\"product_name\"] = dataset[\"product_name\"]\n",
    "\n",
    "(X_with_labels[X_with_labels[\"labels\"]==0])[[\n",
    "    \"energy-kcal_100g\",\n",
    "    \"energy_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\"\n",
    "]].head()\n",
    "\n",
    "for col in X_cap.columns:\n",
    "    print(col)\n",
    "    for _ in set(label):\n",
    "        print(f\"\\tLabel {_}\")\n",
    "\n",
    "#         Median\n",
    "        print(f\"\\t\\tMedian = {(X_with_labels[X_with_labels['labels']==_])[[ col ]].median()[0] }\" )\n",
    "\n",
    "#         Min    \n",
    "        print(f\"\\t\\tMin = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].min()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].min()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "            \n",
    "\n",
    "#         Max\n",
    "        print(f\"\\t\\tMax = { (X_with_labels[X_with_labels['labels']==_])[[ col ]].max()[0] }\")\n",
    "        for product in ( X_with_labels[ (X_with_labels[ col ] == (X_with_labels[X_with_labels[\"labels\"]==_])[[ col ]].max()[0] ) & (X_with_labels[\"labels\"]==_) ] )[\"product_name\"]:\n",
    "            product_line = dataset[ dataset['product_name'] == product]\n",
    "            print(f\"\\t\\t\\t{product_line['product_name'].values[0]}\")\n",
    "            for column in dataset.columns.tolist():\n",
    "                print(f\"\\t\\t\\t\\t{column} : {product_line[column].values[0]}\")\n",
    "            break\n",
    "\n",
    "        print(\"----------\")\n",
    "\n",
    "\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-document",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-behavior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
